{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import io "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('F://Data_set/cancer_datasets.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.drop(labels=['id','Unnamed: 32'],axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide the Dataset into dependent and independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop(labels=['id','diagnosis','Unnamed: 32'],axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['diagnosis'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the Dataset into traning set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train) \n",
    "x_test = scaler.fit_transform(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15036482, -0.39064196, -1.12855021, ..., -0.75798367,\n",
       "        -0.01614761, -0.38503402],\n",
       "       [-0.93798972,  0.68051405, -0.94820146, ..., -0.60687023,\n",
       "         0.09669004, -0.38615797],\n",
       "       [ 0.574121  , -1.03333557,  0.51394098, ..., -0.02371948,\n",
       "        -0.20050207, -0.75144254],\n",
       "       ...,\n",
       "       [-1.32422924, -0.20048168, -1.31754581, ..., -0.97974953,\n",
       "        -0.71542314, -0.11978123],\n",
       "       [-1.24380987, -0.2245526 , -1.28007609, ..., -1.75401433,\n",
       "        -1.58157125, -1.00601779],\n",
       "       [-0.73694129,  1.14989702, -0.71226578, ..., -0.27460457,\n",
       "        -1.25895095,  0.21515662]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22609091,  0.14299357, -0.16219992, ...,  1.33438591,\n",
       "         1.22101459,  1.32977555],\n",
       "       [-0.28072076,  1.13113906, -0.34954245, ..., -0.81952682,\n",
       "        -0.77541863, -0.94570364],\n",
       "       [-0.04782508, -0.87231025, -0.12299829, ..., -0.49120548,\n",
       "        -1.31433312, -0.98696059],\n",
       "       ...,\n",
       "       [ 1.7233322 , -0.06173848,  1.70132185, ...,  1.51554921,\n",
       "         0.25341812, -0.26496405],\n",
       "       [ 1.18565945,  0.15552818,  1.16487847, ...,  0.53103066,\n",
       "         0.32690646, -0.37709831],\n",
       "       [ 0.24545096, -0.64668718,  0.25416267, ..., -0.19956228,\n",
       "        -1.2425945 , -0.01424877]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop = Dropout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create first input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=1.0)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) \n",
    "\n",
    "# Adding Dropout\n",
    "model.add(Dropout(p=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Second Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=1.0)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=16,init='uniform',activation='relu'))\n",
    "# Adding Dropout\n",
    "model.add(Dropout(p=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 1,init='uniform',activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile Our ANN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traning and Testing of Our Model With Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5846\n",
      "Epoch 2/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.6911 - accuracy: 0.6967\n",
      "Epoch 3/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6885 - accuracy: 0.7978\n",
      "Epoch 4/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6847 - accuracy: 0.8571\n",
      "Epoch 5/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6792 - accuracy: 0.9165\n",
      "Epoch 6/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.6712 - accuracy: 0.9297\n",
      "Epoch 7/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.6601 - accuracy: 0.9275\n",
      "Epoch 8/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6446 - accuracy: 0.9363\n",
      "Epoch 9/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6241 - accuracy: 0.9385\n",
      "Epoch 10/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.5974 - accuracy: 0.9407\n",
      "Epoch 11/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.5665 - accuracy: 0.9473\n",
      "Epoch 12/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.5287 - accuracy: 0.9495\n",
      "Epoch 13/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.4879 - accuracy: 0.9516\n",
      "Epoch 14/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.4433 - accuracy: 0.9495\n",
      "Epoch 15/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.3975 - accuracy: 0.9560\n",
      "Epoch 16/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.3532 - accuracy: 0.9626\n",
      "Epoch 17/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.3112 - accuracy: 0.9648\n",
      "Epoch 18/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.2736 - accuracy: 0.9670\n",
      "Epoch 19/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.2401 - accuracy: 0.9670\n",
      "Epoch 20/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.2126 - accuracy: 0.9692\n",
      "Epoch 21/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.1899 - accuracy: 0.9714\n",
      "Epoch 22/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1705 - accuracy: 0.9736\n",
      "Epoch 23/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.1555 - accuracy: 0.9714\n",
      "Epoch 24/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1427 - accuracy: 0.9736\n",
      "Epoch 25/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1321 - accuracy: 0.9736\n",
      "Epoch 26/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1239 - accuracy: 0.9736\n",
      "Epoch 27/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1161 - accuracy: 0.9736\n",
      "Epoch 28/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.1101 - accuracy: 0.9736\n",
      "Epoch 29/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1049 - accuracy: 0.9736\n",
      "Epoch 30/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1004 - accuracy: 0.9758\n",
      "Epoch 31/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0963 - accuracy: 0.9758\n",
      "Epoch 32/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0930 - accuracy: 0.9780\n",
      "Epoch 33/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0899 - accuracy: 0.9780\n",
      "Epoch 34/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0870 - accuracy: 0.9802\n",
      "Epoch 35/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0844 - accuracy: 0.9802\n",
      "Epoch 36/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0821 - accuracy: 0.9802\n",
      "Epoch 37/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0800 - accuracy: 0.9802\n",
      "Epoch 38/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0781 - accuracy: 0.9802\n",
      "Epoch 39/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0763 - accuracy: 0.9802\n",
      "Epoch 40/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0746 - accuracy: 0.9846\n",
      "Epoch 41/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0732 - accuracy: 0.9868\n",
      "Epoch 42/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0718 - accuracy: 0.9868\n",
      "Epoch 43/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0706 - accuracy: 0.9868\n",
      "Epoch 44/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0694 - accuracy: 0.9868\n",
      "Epoch 45/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0683 - accuracy: 0.9868\n",
      "Epoch 46/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0673 - accuracy: 0.9868\n",
      "Epoch 47/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0663 - accuracy: 0.9868\n",
      "Epoch 48/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0654 - accuracy: 0.9868\n",
      "Epoch 49/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.0646 - accuracy: 0.9868\n",
      "Epoch 50/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0637 - accuracy: 0.9868\n",
      "Epoch 51/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0629 - accuracy: 0.9868\n",
      "Epoch 52/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0621 - accuracy: 0.9868\n",
      "Epoch 53/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0614 - accuracy: 0.9890\n",
      "Epoch 54/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0606 - accuracy: 0.9890\n",
      "Epoch 55/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0600 - accuracy: 0.9890\n",
      "Epoch 56/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0594 - accuracy: 0.9890\n",
      "Epoch 57/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0587 - accuracy: 0.9890\n",
      "Epoch 58/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0581 - accuracy: 0.9890\n",
      "Epoch 59/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0576 - accuracy: 0.9890\n",
      "Epoch 60/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0571 - accuracy: 0.9890\n",
      "Epoch 61/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0565 - accuracy: 0.9890\n",
      "Epoch 62/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0560 - accuracy: 0.9890\n",
      "Epoch 63/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0555 - accuracy: 0.9890\n",
      "Epoch 64/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0550 - accuracy: 0.9890\n",
      "Epoch 65/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0545 - accuracy: 0.9890\n",
      "Epoch 66/150\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.0541 - accuracy: 0.9890\n",
      "Epoch 67/150\n",
      "455/455 [==============================] - 0s 48us/step - loss: 0.0537 - accuracy: 0.9890\n",
      "Epoch 68/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0533 - accuracy: 0.9890\n",
      "Epoch 69/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0529 - accuracy: 0.9890\n",
      "Epoch 70/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.0525 - accuracy: 0.9890\n",
      "Epoch 71/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0521 - accuracy: 0.9890\n",
      "Epoch 72/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0518 - accuracy: 0.9890\n",
      "Epoch 73/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0513 - accuracy: 0.9890\n",
      "Epoch 74/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0509 - accuracy: 0.9890\n",
      "Epoch 75/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0506 - accuracy: 0.9890\n",
      "Epoch 76/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0501 - accuracy: 0.9890\n",
      "Epoch 77/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0499 - accuracy: 0.9890\n",
      "Epoch 78/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0494 - accuracy: 0.9890\n",
      "Epoch 79/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0490 - accuracy: 0.9890\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 33us/step - loss: 0.0487 - accuracy: 0.9890\n",
      "Epoch 81/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0483 - accuracy: 0.9890\n",
      "Epoch 82/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0480 - accuracy: 0.9890\n",
      "Epoch 83/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0476 - accuracy: 0.9890\n",
      "Epoch 84/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0473 - accuracy: 0.9890\n",
      "Epoch 85/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0470 - accuracy: 0.9890\n",
      "Epoch 86/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0467 - accuracy: 0.9890\n",
      "Epoch 87/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0463 - accuracy: 0.9890\n",
      "Epoch 88/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0460 - accuracy: 0.9890\n",
      "Epoch 89/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0457 - accuracy: 0.9890\n",
      "Epoch 90/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0455 - accuracy: 0.9890\n",
      "Epoch 91/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0451 - accuracy: 0.9890\n",
      "Epoch 92/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0448 - accuracy: 0.9890\n",
      "Epoch 93/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0445 - accuracy: 0.9890\n",
      "Epoch 94/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0443 - accuracy: 0.9890\n",
      "Epoch 95/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0440 - accuracy: 0.9890\n",
      "Epoch 96/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0437 - accuracy: 0.9890\n",
      "Epoch 97/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0435 - accuracy: 0.9890\n",
      "Epoch 98/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0432 - accuracy: 0.9890\n",
      "Epoch 99/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0430 - accuracy: 0.9890\n",
      "Epoch 100/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0427 - accuracy: 0.9890\n",
      "Epoch 101/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0425 - accuracy: 0.9912\n",
      "Epoch 102/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0422 - accuracy: 0.9912\n",
      "Epoch 103/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0420 - accuracy: 0.9912\n",
      "Epoch 104/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0417 - accuracy: 0.9912\n",
      "Epoch 105/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0415 - accuracy: 0.9912\n",
      "Epoch 106/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0413 - accuracy: 0.9912\n",
      "Epoch 107/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0410 - accuracy: 0.9912\n",
      "Epoch 108/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0408 - accuracy: 0.9912\n",
      "Epoch 109/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0406 - accuracy: 0.9912\n",
      "Epoch 110/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0403 - accuracy: 0.9912\n",
      "Epoch 111/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0402 - accuracy: 0.9912\n",
      "Epoch 112/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0399 - accuracy: 0.9912\n",
      "Epoch 113/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0396 - accuracy: 0.9912\n",
      "Epoch 114/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0394 - accuracy: 0.9912\n",
      "Epoch 115/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0392 - accuracy: 0.9912\n",
      "Epoch 116/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0389 - accuracy: 0.9912\n",
      "Epoch 117/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0387 - accuracy: 0.9912\n",
      "Epoch 118/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0386 - accuracy: 0.9912\n",
      "Epoch 119/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0383 - accuracy: 0.9912\n",
      "Epoch 120/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0381 - accuracy: 0.9912\n",
      "Epoch 121/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0379 - accuracy: 0.9912\n",
      "Epoch 122/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0377 - accuracy: 0.9912\n",
      "Epoch 123/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0375 - accuracy: 0.9912\n",
      "Epoch 124/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0373 - accuracy: 0.9912\n",
      "Epoch 125/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0371 - accuracy: 0.9912\n",
      "Epoch 126/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0369 - accuracy: 0.9912\n",
      "Epoch 127/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0367 - accuracy: 0.9912\n",
      "Epoch 128/150\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 1.00 - 0s 33us/step - loss: 0.0365 - accuracy: 0.9912\n",
      "Epoch 129/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0363 - accuracy: 0.9912\n",
      "Epoch 130/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0361 - accuracy: 0.9912\n",
      "Epoch 131/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0359 - accuracy: 0.9912\n",
      "Epoch 132/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0357 - accuracy: 0.9912\n",
      "Epoch 133/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0356 - accuracy: 0.9912\n",
      "Epoch 134/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0354 - accuracy: 0.9912\n",
      "Epoch 135/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0352 - accuracy: 0.9912\n",
      "Epoch 136/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0350 - accuracy: 0.9912\n",
      "Epoch 137/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0348 - accuracy: 0.9912\n",
      "Epoch 138/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0347 - accuracy: 0.9912\n",
      "Epoch 139/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0345 - accuracy: 0.9912\n",
      "Epoch 140/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0343 - accuracy: 0.9912\n",
      "Epoch 141/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0342 - accuracy: 0.9912\n",
      "Epoch 142/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0339 - accuracy: 0.9912\n",
      "Epoch 143/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0337 - accuracy: 0.9912\n",
      "Epoch 144/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0336 - accuracy: 0.9912\n",
      "Epoch 145/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0334 - accuracy: 0.9912\n",
      "Epoch 146/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0332 - accuracy: 0.9912\n",
      "Epoch 147/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0330 - accuracy: 0.9912\n",
      "Epoch 148/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0328 - accuracy: 0.9912\n",
      "Epoch 149/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0327 - accuracy: 0.9912\n",
      "Epoch 150/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0325 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2235a9f0788>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=100,nb_epoch=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22609091  0.14299357 -0.16219992 ...  1.33438591  1.22101459\n",
      "   1.32977555]\n",
      " [-0.28072076  1.13113906 -0.34954245 ... -0.81952682 -0.77541863\n",
      "  -0.94570364]\n",
      " [-0.04782508 -0.87231025 -0.12299829 ... -0.49120548 -1.31433312\n",
      "  -0.98696059]\n",
      " ...\n",
      " [ 1.7233322  -0.06173848  1.70132185 ...  1.51554921  0.25341812\n",
      "  -0.26496405]\n",
      " [ 1.18565945  0.15552818  1.16487847 ...  0.53103066  0.32690646\n",
      "  -0.37709831]\n",
      " [ 0.24545096 -0.64668718  0.25416267 ... -0.19956228 -1.2425945\n",
      "  -0.01424877]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the test set result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test) \n",
    "\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Accuracy after traning\n",
    "\n",
    "(65+44)/114 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(64+44)/114 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
