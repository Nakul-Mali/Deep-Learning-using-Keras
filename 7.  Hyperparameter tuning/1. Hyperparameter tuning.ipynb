{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('F://Data_Set/cancer_datasets.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Unwanted Column from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing data into dependent and independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder() \n",
    "\n",
    "y = le.fit_transform(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the Dataset into Traning set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1,random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train) \n",
    "x_test = scaler.fit_transform(x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Keras Libeary for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crating ANN Model and adding layers into them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 1st input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding 2nd layer into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 16,activation='relu')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Output layer into the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=1,activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiler Classifier / Compile Our ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Our ANN with traning and testing with diffrent ephoc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakul Raje\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.6677 - accuracy: 0.7031\n",
      "Epoch 2/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.6201 - accuracy: 0.8770\n",
      "Epoch 3/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.5744 - accuracy: 0.9141\n",
      "Epoch 4/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.5237 - accuracy: 0.9316\n",
      "Epoch 5/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.4718 - accuracy: 0.9355\n",
      "Epoch 6/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.4217 - accuracy: 0.9355\n",
      "Epoch 7/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.3768 - accuracy: 0.9414\n",
      "Epoch 8/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.3349 - accuracy: 0.9453\n",
      "Epoch 9/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.2988 - accuracy: 0.9492\n",
      "Epoch 10/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.2678 - accuracy: 0.9512\n",
      "Epoch 11/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.2413 - accuracy: 0.9531\n",
      "Epoch 12/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.2187 - accuracy: 0.9492\n",
      "Epoch 13/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.1994 - accuracy: 0.9492\n",
      "Epoch 14/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.1837 - accuracy: 0.9570\n",
      "Epoch 15/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.1696 - accuracy: 0.9570\n",
      "Epoch 16/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.1580 - accuracy: 0.9590\n",
      "Epoch 17/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.1477 - accuracy: 0.9609\n",
      "Epoch 18/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.1389 - accuracy: 0.9609\n",
      "Epoch 19/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.1310 - accuracy: 0.9648\n",
      "Epoch 20/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.1242 - accuracy: 0.9688\n",
      "Epoch 21/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.1184 - accuracy: 0.9688\n",
      "Epoch 22/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.1125 - accuracy: 0.9727\n",
      "Epoch 23/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.1075 - accuracy: 0.9746\n",
      "Epoch 24/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.1030 - accuracy: 0.9766\n",
      "Epoch 25/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0990 - accuracy: 0.9766\n",
      "Epoch 26/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0952 - accuracy: 0.9785\n",
      "Epoch 27/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0918 - accuracy: 0.9805\n",
      "Epoch 28/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0891 - accuracy: 0.9805\n",
      "Epoch 29/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0862 - accuracy: 0.9805\n",
      "Epoch 30/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0837 - accuracy: 0.9824\n",
      "Epoch 31/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0812 - accuracy: 0.9824\n",
      "Epoch 32/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0790 - accuracy: 0.9863\n",
      "Epoch 33/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0771 - accuracy: 0.9863\n",
      "Epoch 34/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0753 - accuracy: 0.9863\n",
      "Epoch 35/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0737 - accuracy: 0.9863\n",
      "Epoch 36/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0723 - accuracy: 0.9863\n",
      "Epoch 37/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0708 - accuracy: 0.9863\n",
      "Epoch 38/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0694 - accuracy: 0.9863\n",
      "Epoch 39/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0681 - accuracy: 0.9844\n",
      "Epoch 40/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0669 - accuracy: 0.9844\n",
      "Epoch 41/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0659 - accuracy: 0.9844\n",
      "Epoch 42/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0649 - accuracy: 0.9844\n",
      "Epoch 43/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0640 - accuracy: 0.9844\n",
      "Epoch 44/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0631 - accuracy: 0.9844\n",
      "Epoch 45/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0622 - accuracy: 0.9844\n",
      "Epoch 46/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0612 - accuracy: 0.9844\n",
      "Epoch 47/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0604 - accuracy: 0.9844\n",
      "Epoch 48/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0594 - accuracy: 0.9844\n",
      "Epoch 49/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0588 - accuracy: 0.9863\n",
      "Epoch 50/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0581 - accuracy: 0.9863\n",
      "Epoch 51/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0571 - accuracy: 0.9863\n",
      "Epoch 52/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0563 - accuracy: 0.9863\n",
      "Epoch 53/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0555 - accuracy: 0.9863\n",
      "Epoch 54/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0549 - accuracy: 0.9863\n",
      "Epoch 55/150\n",
      "512/512 [==============================] - 0s 62us/step - loss: 0.0541 - accuracy: 0.9863\n",
      "Epoch 56/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0534 - accuracy: 0.9883\n",
      "Epoch 57/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0525 - accuracy: 0.9883\n",
      "Epoch 58/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0519 - accuracy: 0.9883\n",
      "Epoch 59/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0518 - accuracy: 0.9883\n",
      "Epoch 60/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0511 - accuracy: 0.9883\n",
      "Epoch 61/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0501 - accuracy: 0.9883\n",
      "Epoch 62/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0493 - accuracy: 0.9883\n",
      "Epoch 63/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0491 - accuracy: 0.9883\n",
      "Epoch 64/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0487 - accuracy: 0.9883\n",
      "Epoch 65/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0482 - accuracy: 0.9883\n",
      "Epoch 66/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0476 - accuracy: 0.9883\n",
      "Epoch 67/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0471 - accuracy: 0.9902\n",
      "Epoch 68/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0466 - accuracy: 0.9922\n",
      "Epoch 69/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0462 - accuracy: 0.9922\n",
      "Epoch 70/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0458 - accuracy: 0.9922\n",
      "Epoch 71/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0447 - accuracy: 0.9922\n",
      "Epoch 72/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0443 - accuracy: 0.9922\n",
      "Epoch 73/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0438 - accuracy: 0.9922\n",
      "Epoch 74/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0434 - accuracy: 0.9922\n",
      "Epoch 75/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0431 - accuracy: 0.9922\n",
      "Epoch 76/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0427 - accuracy: 0.9922\n",
      "Epoch 77/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0422 - accuracy: 0.9922\n",
      "Epoch 78/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0419 - accuracy: 0.9922\n",
      "Epoch 79/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0415 - accuracy: 0.9922\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 31us/step - loss: 0.0416 - accuracy: 0.9922\n",
      "Epoch 81/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0412 - accuracy: 0.9922\n",
      "Epoch 82/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0406 - accuracy: 0.9922\n",
      "Epoch 83/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0400 - accuracy: 0.9922\n",
      "Epoch 84/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0395 - accuracy: 0.9922\n",
      "Epoch 85/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0391 - accuracy: 0.9922\n",
      "Epoch 86/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0387 - accuracy: 0.9922\n",
      "Epoch 87/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0386 - accuracy: 0.9922\n",
      "Epoch 88/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0378 - accuracy: 0.9922\n",
      "Epoch 89/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0374 - accuracy: 0.9922\n",
      "Epoch 90/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0369 - accuracy: 0.9922\n",
      "Epoch 91/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0365 - accuracy: 0.9922\n",
      "Epoch 92/150\n",
      "512/512 [==============================] - 0s 16us/step - loss: 0.0362 - accuracy: 0.9922\n",
      "Epoch 93/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0361 - accuracy: 0.9922\n",
      "Epoch 94/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0356 - accuracy: 0.9922\n",
      "Epoch 95/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0352 - accuracy: 0.9922\n",
      "Epoch 96/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0348 - accuracy: 0.9922\n",
      "Epoch 97/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0343 - accuracy: 0.9922\n",
      "Epoch 98/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0339 - accuracy: 0.9922\n",
      "Epoch 99/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0336 - accuracy: 0.9922\n",
      "Epoch 100/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0332 - accuracy: 0.9922\n",
      "Epoch 101/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0329 - accuracy: 0.9922\n",
      "Epoch 102/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0327 - accuracy: 0.9922\n",
      "Epoch 103/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0324 - accuracy: 0.9922\n",
      "Epoch 104/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0321 - accuracy: 0.9922\n",
      "Epoch 105/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0318 - accuracy: 0.9922\n",
      "Epoch 106/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0314 - accuracy: 0.9922\n",
      "Epoch 107/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0311 - accuracy: 0.9922\n",
      "Epoch 108/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0310 - accuracy: 0.9922\n",
      "Epoch 109/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0309 - accuracy: 0.9941\n",
      "Epoch 110/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0306 - accuracy: 0.9941\n",
      "Epoch 111/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0298 - accuracy: 0.9941\n",
      "Epoch 112/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0297 - accuracy: 0.9941\n",
      "Epoch 113/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0292 - accuracy: 0.9922\n",
      "Epoch 114/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0289 - accuracy: 0.9922\n",
      "Epoch 115/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0286 - accuracy: 0.9922\n",
      "Epoch 116/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0283 - accuracy: 0.9922\n",
      "Epoch 117/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0280 - accuracy: 0.9922\n",
      "Epoch 118/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0282 - accuracy: 0.9922\n",
      "Epoch 119/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0272 - accuracy: 0.9922\n",
      "Epoch 120/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0277 - accuracy: 0.9941\n",
      "Epoch 121/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0277 - accuracy: 0.9941\n",
      "Epoch 122/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0269 - accuracy: 0.9941\n",
      "Epoch 123/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0265 - accuracy: 0.9941\n",
      "Epoch 124/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0262 - accuracy: 0.9941\n",
      "Epoch 125/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0259 - accuracy: 0.9941\n",
      "Epoch 126/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0257 - accuracy: 0.9941\n",
      "Epoch 127/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0256 - accuracy: 0.9941\n",
      "Epoch 128/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0253 - accuracy: 0.9941\n",
      "Epoch 129/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0251 - accuracy: 0.9941\n",
      "Epoch 130/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0249 - accuracy: 0.9941\n",
      "Epoch 131/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0247 - accuracy: 0.9941\n",
      "Epoch 132/150\n",
      "512/512 [==============================] - 0s 16us/step - loss: 0.0244 - accuracy: 0.9941\n",
      "Epoch 133/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0242 - accuracy: 0.9941\n",
      "Epoch 134/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0241 - accuracy: 0.9941\n",
      "Epoch 135/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0238 - accuracy: 0.9941\n",
      "Epoch 136/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0237 - accuracy: 0.9941\n",
      "Epoch 137/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0234 - accuracy: 0.9941\n",
      "Epoch 138/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0238 - accuracy: 0.9941\n",
      "Epoch 139/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0238 - accuracy: 0.9941\n",
      "Epoch 140/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0233 - accuracy: 0.9941\n",
      "Epoch 141/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0227 - accuracy: 0.9941\n",
      "Epoch 142/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0226 - accuracy: 0.9941\n",
      "Epoch 143/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0227 - accuracy: 0.9922\n",
      "Epoch 144/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0228 - accuracy: 0.9922\n",
      "Epoch 145/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0224 - accuracy: 0.9922\n",
      "Epoch 146/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0218 - accuracy: 0.9922\n",
      "Epoch 147/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0215 - accuracy: 0.9941\n",
      "Epoch 148/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0212 - accuracy: 0.9941\n",
      "Epoch 149/150\n",
      "512/512 [==============================] - 0s 20us/step - loss: 0.0212 - accuracy: 0.9941\n",
      "Epoch 150/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0210 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2578e6f5a08>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=100,nb_epoch=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19207516,  0.21655218, -0.11542614, ...,  1.60315155,\n",
       "         1.38812047,  1.39561107],\n",
       "       [-0.24797128,  1.29875111, -0.31114085, ..., -0.76400211,\n",
       "        -0.79834577, -0.93437281],\n",
       "       [-0.00967731, -0.89539007, -0.07447263, ..., -0.40317641,\n",
       "        -1.38855752, -0.97661799],\n",
       "       ...,\n",
       "       [-0.46861385,  0.07241152, -0.46935075, ..., -0.49962508,\n",
       "        -0.33652424, -0.40576652],\n",
       "       [-0.75986205, -0.81073603, -0.78878818, ..., -0.67538685,\n",
       "        -0.01842311,  0.13529668],\n",
       "       [-0.80399056,  1.71744542, -0.84310547, ..., -1.40405566,\n",
       "        -0.02225565, -0.77243298]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Test set result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred = (y_pred > 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the onfusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To See the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('hm.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
