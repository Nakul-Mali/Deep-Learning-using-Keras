{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('F:/Data_Set/cancer_datasets.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst  Unnamed: 32\n",
       "0    842302         M        17.99  ...          0.4601                  0.11890          NaN\n",
       "1    842517         M        20.57  ...          0.2750                  0.08902          NaN\n",
       "2  84300903         M        19.69  ...          0.3613                  0.08758          NaN\n",
       "3  84348301         M        11.42  ...          0.6638                  0.17300          NaN\n",
       "4  84358402         M        20.29  ...          0.2364                  0.07678          NaN\n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide the data into dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop(labels=['id','diagnosis','Unnamed: 32'],axis=1) \n",
    "#x = dataset.iloc[:,2:33].values\n",
    "#print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['diagnosis'] \n",
    "#y = dataset.iloc[:,1].values \n",
    "#print(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Categorical data of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder() \n",
    "\n",
    "y =  le.fit_transform(y)\n",
    "\n",
    "#print(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To see the Quantity of Benign and Malignanat graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign 357\n",
      "Malignanat 212\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(dataset['diagnosis'],label = 'count')  \n",
    "B,M = dataset['diagnosis'].value_counts()\n",
    "print('Benign',B) \n",
    "print('Malignanat',M) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into traning and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train) \n",
    "x_test = scaler.fit_transform(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15036482, -0.39064196, -1.12855021, ..., -0.75798367,\n",
       "        -0.01614761, -0.38503402],\n",
       "       [-0.93798972,  0.68051405, -0.94820146, ..., -0.60687023,\n",
       "         0.09669004, -0.38615797],\n",
       "       [ 0.574121  , -1.03333557,  0.51394098, ..., -0.02371948,\n",
       "        -0.20050207, -0.75144254],\n",
       "       ...,\n",
       "       [-1.32422924, -0.20048168, -1.31754581, ..., -0.97974953,\n",
       "        -0.71542314, -0.11978123],\n",
       "       [-1.24380987, -0.2245526 , -1.28007609, ..., -1.75401433,\n",
       "        -1.58157125, -1.00601779],\n",
       "       [-0.73694129,  1.14989702, -0.71226578, ..., -0.27460457,\n",
       "        -1.25895095,  0.21515662]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22609091,  0.14299357, -0.16219992, ...,  1.33438591,\n",
       "         1.22101459,  1.32977555],\n",
       "       [-0.28072076,  1.13113906, -0.34954245, ..., -0.81952682,\n",
       "        -0.77541863, -0.94570364],\n",
       "       [-0.04782508, -0.87231025, -0.12299829, ..., -0.49120548,\n",
       "        -1.31433312, -0.98696059],\n",
       "       ...,\n",
       "       [ 1.7233322 , -0.06173848,  1.70132185, ...,  1.51554921,\n",
       "         0.25341812, -0.26496405],\n",
       "       [ 1.18565945,  0.15552818,  1.16487847, ...,  0.53103066,\n",
       "         0.32690646, -0.37709831],\n",
       "       [ 0.24545096, -0.64668718,  0.25416267, ..., -0.19956228,\n",
       "        -1.2425945 , -0.01424877]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create First input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Second Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=16,init='uniform',activation='relu')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 1,init='uniform',activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Our ANN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traning and Testing of Model with epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "455/455 [==============================] - 0s 465us/step - loss: 0.6928 - accuracy: 0.6374\n",
      "Epoch 2/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.6920 - accuracy: 0.6374\n",
      "Epoch 3/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6909 - accuracy: 0.6374\n",
      "Epoch 4/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.6896 - accuracy: 0.6374\n",
      "Epoch 5/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.6874 - accuracy: 0.6374\n",
      "Epoch 6/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6844 - accuracy: 0.6374\n",
      "Epoch 7/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.6796 - accuracy: 0.6374\n",
      "Epoch 8/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.6725 - accuracy: 0.6374\n",
      "Epoch 9/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.6619 - accuracy: 0.6374\n",
      "Epoch 10/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6466 - accuracy: 0.6374\n",
      "Epoch 11/150\n",
      "455/455 [==============================] - 0s 48us/step - loss: 0.6261 - accuracy: 0.6396\n",
      "Epoch 12/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.5985 - accuracy: 0.6418\n",
      "Epoch 13/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.5628 - accuracy: 0.6835\n",
      "Epoch 14/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.5215 - accuracy: 0.7714\n",
      "Epoch 15/150\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.4687 - accuracy: 0.88 - 0s 44us/step - loss: 0.4755 - accuracy: 0.8593\n",
      "Epoch 16/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.4287 - accuracy: 0.9121\n",
      "Epoch 17/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.3871 - accuracy: 0.9473\n",
      "Epoch 18/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.3497 - accuracy: 0.9582\n",
      "Epoch 19/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.3185 - accuracy: 0.9648\n",
      "Epoch 20/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.2907 - accuracy: 0.9714\n",
      "Epoch 21/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.2652 - accuracy: 0.9758\n",
      "Epoch 22/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.2412 - accuracy: 0.9780\n",
      "Epoch 23/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.2189 - accuracy: 0.9780\n",
      "Epoch 24/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1970 - accuracy: 0.9780\n",
      "Epoch 25/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.1782 - accuracy: 0.9780\n",
      "Epoch 26/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.1611 - accuracy: 0.9780\n",
      "Epoch 27/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1458 - accuracy: 0.9802\n",
      "Epoch 28/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.1331 - accuracy: 0.9802\n",
      "Epoch 29/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.1227 - accuracy: 0.9802\n",
      "Epoch 30/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.1135 - accuracy: 0.9802\n",
      "Epoch 31/150\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.98 - 0s 46us/step - loss: 0.1065 - accuracy: 0.9780\n",
      "Epoch 32/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1005 - accuracy: 0.9780\n",
      "Epoch 33/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0954 - accuracy: 0.9780\n",
      "Epoch 34/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0911 - accuracy: 0.9802\n",
      "Epoch 35/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0875 - accuracy: 0.9802\n",
      "Epoch 36/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0843 - accuracy: 0.9824\n",
      "Epoch 37/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0816 - accuracy: 0.9824\n",
      "Epoch 38/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0791 - accuracy: 0.9824\n",
      "Epoch 39/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0771 - accuracy: 0.9824\n",
      "Epoch 40/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0750 - accuracy: 0.9824\n",
      "Epoch 41/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0730 - accuracy: 0.9824\n",
      "Epoch 42/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0709 - accuracy: 0.9824\n",
      "Epoch 43/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0693 - accuracy: 0.9824\n",
      "Epoch 44/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0674 - accuracy: 0.9868\n",
      "Epoch 45/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0663 - accuracy: 0.9890\n",
      "Epoch 46/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0647 - accuracy: 0.9890\n",
      "Epoch 47/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0635 - accuracy: 0.9890\n",
      "Epoch 48/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0623 - accuracy: 0.9890\n",
      "Epoch 49/150\n",
      "455/455 [==============================] - 0s 48us/step - loss: 0.0612 - accuracy: 0.9890\n",
      "Epoch 50/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0602 - accuracy: 0.9890\n",
      "Epoch 51/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0593 - accuracy: 0.9890\n",
      "Epoch 52/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0583 - accuracy: 0.9890\n",
      "Epoch 53/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0575 - accuracy: 0.9890\n",
      "Epoch 54/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0566 - accuracy: 0.9890\n",
      "Epoch 55/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0559 - accuracy: 0.9890\n",
      "Epoch 56/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0551 - accuracy: 0.9890\n",
      "Epoch 57/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0544 - accuracy: 0.9890\n",
      "Epoch 58/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0536 - accuracy: 0.9890\n",
      "Epoch 59/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0530 - accuracy: 0.9890\n",
      "Epoch 60/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0522 - accuracy: 0.9890\n",
      "Epoch 61/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0516 - accuracy: 0.9890\n",
      "Epoch 62/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0509 - accuracy: 0.9890\n",
      "Epoch 63/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0504 - accuracy: 0.9890\n",
      "Epoch 64/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0498 - accuracy: 0.9890\n",
      "Epoch 65/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0493 - accuracy: 0.9890\n",
      "Epoch 66/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0486 - accuracy: 0.9890\n",
      "Epoch 67/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0481 - accuracy: 0.9890\n",
      "Epoch 68/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0476 - accuracy: 0.9890\n",
      "Epoch 69/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0471 - accuracy: 0.9890\n",
      "Epoch 70/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0465 - accuracy: 0.9890\n",
      "Epoch 71/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0460 - accuracy: 0.9890\n",
      "Epoch 72/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0456 - accuracy: 0.9890\n",
      "Epoch 73/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0451 - accuracy: 0.9890\n",
      "Epoch 74/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0446 - accuracy: 0.9890\n",
      "Epoch 75/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0442 - accuracy: 0.9890\n",
      "Epoch 76/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0438 - accuracy: 0.9890\n",
      "Epoch 77/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0433 - accuracy: 0.9912\n",
      "Epoch 78/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0429 - accuracy: 0.9912\n",
      "Epoch 79/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0425 - accuracy: 0.9912\n",
      "Epoch 80/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0421 - accuracy: 0.9912\n",
      "Epoch 81/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0416 - accuracy: 0.9912\n",
      "Epoch 82/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0412 - accuracy: 0.9912\n",
      "Epoch 83/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0409 - accuracy: 0.9912\n",
      "Epoch 84/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0403 - accuracy: 0.9912\n",
      "Epoch 85/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0400 - accuracy: 0.9912\n",
      "Epoch 86/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0395 - accuracy: 0.9912\n",
      "Epoch 87/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0391 - accuracy: 0.9912\n",
      "Epoch 88/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0387 - accuracy: 0.9912\n",
      "Epoch 89/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0384 - accuracy: 0.9912\n",
      "Epoch 90/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0379 - accuracy: 0.9912\n",
      "Epoch 91/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0376 - accuracy: 0.9912\n",
      "Epoch 92/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0371 - accuracy: 0.9912\n",
      "Epoch 93/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0367 - accuracy: 0.9912\n",
      "Epoch 94/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0363 - accuracy: 0.9912\n",
      "Epoch 95/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0360 - accuracy: 0.9912\n",
      "Epoch 96/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0356 - accuracy: 0.9912\n",
      "Epoch 97/150\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.0352 - accuracy: 0.9912\n",
      "Epoch 98/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0348 - accuracy: 0.9912\n",
      "Epoch 99/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0345 - accuracy: 0.9912\n",
      "Epoch 100/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0341 - accuracy: 0.9912\n",
      "Epoch 101/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0338 - accuracy: 0.9912\n",
      "Epoch 102/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0336 - accuracy: 0.9912\n",
      "Epoch 103/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0332 - accuracy: 0.9912\n",
      "Epoch 104/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0329 - accuracy: 0.9912\n",
      "Epoch 105/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0326 - accuracy: 0.9912\n",
      "Epoch 106/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.0323 - accuracy: 0.9912\n",
      "Epoch 107/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0320 - accuracy: 0.9912\n",
      "Epoch 108/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0317 - accuracy: 0.9912\n",
      "Epoch 109/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0314 - accuracy: 0.9912\n",
      "Epoch 110/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0311 - accuracy: 0.9912\n",
      "Epoch 111/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0308 - accuracy: 0.9912\n",
      "Epoch 112/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0305 - accuracy: 0.9912\n",
      "Epoch 113/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0303 - accuracy: 0.9912\n",
      "Epoch 114/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0299 - accuracy: 0.9912\n",
      "Epoch 115/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0296 - accuracy: 0.9912\n",
      "Epoch 116/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0294 - accuracy: 0.9912\n",
      "Epoch 117/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0290 - accuracy: 0.9912\n",
      "Epoch 118/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0288 - accuracy: 0.9912\n",
      "Epoch 119/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0285 - accuracy: 0.9912\n",
      "Epoch 120/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0282 - accuracy: 0.9912\n",
      "Epoch 121/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0279 - accuracy: 0.9912\n",
      "Epoch 122/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0277 - accuracy: 0.9912\n",
      "Epoch 123/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0274 - accuracy: 0.9912\n",
      "Epoch 124/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0272 - accuracy: 0.9912\n",
      "Epoch 125/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0269 - accuracy: 0.9912\n",
      "Epoch 126/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0266 - accuracy: 0.9912\n",
      "Epoch 127/150\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.99 - 0s 40us/step - loss: 0.0263 - accuracy: 0.9912\n",
      "Epoch 128/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0261 - accuracy: 0.9912\n",
      "Epoch 129/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0258 - accuracy: 0.9912\n",
      "Epoch 130/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0255 - accuracy: 0.9912\n",
      "Epoch 131/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0253 - accuracy: 0.9912\n",
      "Epoch 132/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0250 - accuracy: 0.9912\n",
      "Epoch 133/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0247 - accuracy: 0.9912\n",
      "Epoch 134/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0244 - accuracy: 0.9912\n",
      "Epoch 135/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0242 - accuracy: 0.9912\n",
      "Epoch 136/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0240 - accuracy: 0.9912\n",
      "Epoch 137/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0237 - accuracy: 0.9912\n",
      "Epoch 138/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0235 - accuracy: 0.9912\n",
      "Epoch 139/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0233 - accuracy: 0.9912\n",
      "Epoch 140/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0230 - accuracy: 0.9912\n",
      "Epoch 141/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0227 - accuracy: 0.9912\n",
      "Epoch 142/150\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.99 - 0s 33us/step - loss: 0.0225 - accuracy: 0.9912\n",
      "Epoch 143/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0223 - accuracy: 0.9912\n",
      "Epoch 144/150\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.98 - 0s 40us/step - loss: 0.0220 - accuracy: 0.9912\n",
      "Epoch 145/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0216 - accuracy: 0.9912\n",
      "Epoch 146/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0214 - accuracy: 0.9912\n",
      "Epoch 147/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0211 - accuracy: 0.9912\n",
      "Epoch 148/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0208 - accuracy: 0.9912\n",
      "Epoch 149/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0206 - accuracy: 0.9912\n",
      "Epoch 150/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0204 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13408b7e9b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=100,nb_epoch=150)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22609091  0.14299357 -0.16219992 ...  1.33438591  1.22101459\n",
      "   1.32977555]\n",
      " [-0.28072076  1.13113906 -0.34954245 ... -0.81952682 -0.77541863\n",
      "  -0.94570364]\n",
      " [-0.04782508 -0.87231025 -0.12299829 ... -0.49120548 -1.31433312\n",
      "  -0.98696059]\n",
      " ...\n",
      " [ 1.7233322  -0.06173848  1.70132185 ...  1.51554921  0.25341812\n",
      "  -0.26496405]\n",
      " [ 1.18565945  0.15552818  1.16487847 ...  0.53103066  0.32690646\n",
      "  -0.37709831]\n",
      " [ 0.24545096 -0.64668718  0.25416267 ... -0.19956228 -1.2425945\n",
      "  -0.01424877]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the test set result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test) \n",
    "\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQnElEQVR4nO3df7BcdXnH8feT3HtJgGoSYmIAFexEEFvBTgZBBBGoBXFKphUH1BqdtNc6aJXSClKqg4qio/zojIy9GGO0CgQEQ7GimQi1jBVICmgwKDTGGBKJaPgVkNy7+/SPrHhLLnfvTfZ7z+bk/cqc2d2zu999/kg+8+R7vuecyEwkSeVMqroASao7g1aSCjNoJakwg1aSCjNoJamwntI/MPjwWpc1aAdT9z+26hLUhYa2PRi7OsZ4Mqd35kt3+ffGwo5Wkgor3tFK0oRqNqquYAcGraR6aQxVXcEODFpJtZLZrLqEHRi0kuqladBKUll2tJJUmAfDJKkwO1pJKitddSBJhXkwTJIKc+pAkgrzYJgkFWZHK0mFeTBMkgrzYJgklZXZfXO0Xo9WUr1kc+xbGxExLSKui4j7ImJNRBwdETMiYnlE3N96nN5uHINWUr00m2Pf2rscuDkzDwUOB9YA5wErMnMusKL1elQGraR66VBHGxHPA44DFgFk5rbMfAQ4DVjS+tgSYH67kgxaSfXSGBzzFhH9EbFy2NY/bKSXAr8CFkfEXRHxhYjYB5idmZsAWo+z2pXkwTBJ9TKOVQeZOQAMPMfbPcCfAO/LzNsj4nLGME0wEjtaSfXSuYNhG4ANmXl76/V1bA/ehyJiDkDrcXO7gQxaSfXSoYNhmflL4BcRcUhr14nAj4EbgQWtfQuAZe1KcupAUr109oSF9wFfjYg+YC3wLrY3qEsjYiGwHji93SAGraRaycZg58bKvBuYN8JbJ45nHINWUr14URlJKsxrHUhSYXa0klSYHa0kFWZHK0mFDXnhb0kqy45WkgpzjlaSCrOjlaTC7GglqTA7WkkqzFUHklRYZtUV7MCglVQvztFKUmEGrSQV5sEwSSqs0ai6gh0YtJLqxakDSSrMoJWkwpyjlaSysuk6Wkkqy6kDSSrMVQeSVJgdrSQVZtDuWR57/Ak+cvFlPLD25xDBx84/myP+6OV89dplXPX1f2fy5Mkc95ojOeeshVWXqgpcOfBZTn3jSWz+1cMc8aoTqy6nPjp4UZmIWAc8DjSAocycFxEzgGuAg4B1wFsyc8to4xi0BV182ec55tXzuPSiCxgcHOSp3z7NHavu4ZbbfsD1X76Cvr4+fr3lkarLVEW+/OWlXHHFYhYvvrzqUuql8x3t6zPz4WGvzwNWZObFEXFe6/W5ow3QNmgj4lDgNOAAIIGNwI2ZuWany94DPLF1K6vuWc1FF5wDQG9vL729vVzzjW+y8O1voa+vD4D9pk+rskxV6L9uu52XvOTAqsuon/LLu04Djm89XwLcSpugnTTamxFxLnA1EMAdwJ2t51e1klzPYcODv2T6tOdzwUWX8OZ3nsWHP3kZTz71W9atf5BV96zmzL/5AO886x/50ZqfVF2qVC+Nxpi3iOiPiJXDtv5njZbAdyJi1bD3ZmfmJoDW46x2JbXraBcCr8jMweE7I+IS4F7g4pG+1CqoH+CKz36cv37Hme3qqJ2hRoM1P32A889+D698xaF88rLPs+grS2k0Gjz2+BN8beBSVq/5Kf/wz5/k5msXExFVlyzVQo5j6iAzB4CBUT5yTGZujIhZwPKIuG9nahq1owWawP4j7J/Tem9EmTmQmfMyc96eGLIAL5w1k9kvmMkrX3EoAG84/rX8+KcPMHvWTE563TFEBH982CFEBFseebTiaqUaaebYtzYyc2PrcTNwA3Ak8FBEzAFoPW5uN067oP0AsCIivhURA63tZmAF8P62Ve7BZu43gxfOegE/+/kGAH6w6m7+8KAXc8KxR3PHqrsBWLd+A4NDQ0yf9vwqS5XqJZtj30YREftExB/87jnwBmA1cCOwoPWxBcCydiWNOnWQmTdHxMvYnuIHsH1+dgNwZ2Z23+kXXeb8s9/DuRd+msGhQV60/xw+dv7Z7D11Chd84lLmv/1v6e3t4RMXnOO0wR7q377yOV533NHMnDmDdWtXcuFHP8PiL11ddVm7v84dDJsN3ND699kDfK2ViXcCSyNiIbAeOL3dQJGFb2Q2+PDa7rvCgyo3df9jqy5BXWho24O73HVs/fAZY86cfT569YR0Oa6jlVQvXiZRkgrzMomSVNZ4lndNFINWUr3Y0UpSYQatJBXmhb8lqSzvGSZJpRm0klSYqw4kqTA7WkkqzKCVpLKy4dSBJJVlRytJZbm8S5JKM2glqbDum6I1aCXVSw51X9IatJLqpfty1qCVVC8eDJOk0uxoJaksO1pJKs2OVpLKyqGqK9iRQSupVrrwbuNMqroASeqo5ji2MYiIyRFxV0Tc1Hp9cETcHhH3R8Q1EdHXbgyDVlKtZHPs2xi9H1gz7PWngEszcy6wBVjYbgCDVlKtdDJoI+JA4FTgC63XAZwAXNf6yBJgfrtxDFpJtZKNGPMWEf0RsXLY1v+s4S4DPsjvJxr2Ax7JfOaQ2wbggHY1eTBMUq2M52BYZg4AAyO9FxFvAjZn5qqIOP53u0capt3vGLSSaiWbI2XhTjkG+POIeCMwBXge2zvcaRHR0+pqDwQ2thvIqQNJtdKpOdrM/FBmHpiZBwFnAN/NzLcBtwBvbn1sAbCsXU0GraRayYwxbzvpXODvI+IBts/ZLmr3BacOJNVKiRMWMvNW4NbW87XAkeP5vkErqVaajY7N0XaMQSupVjp4MKxjDFpJtWLQSlJh2X2XozVoJdWLHa0kFbYLy7aKMWgl1UrDVQeSVJYdrSQV5hytJBXmqgNJKsyOVpIKazS771pZBq2kWnHqQJIKa7rqQJLKcnmXJBW2R04dTH/xiaV/QruhX595aNUlqKacOpCkwlx1IEmFdeHMgUErqV6cOpCkwlx1IEmFFbgJ7i4zaCXVSmJHK0lFDTl1IElldWNH230LziRpFzTHsY0mIqZExB0RcU9E3BsRF7b2HxwRt0fE/RFxTUT0tavJoJVUK0mMeWvjaeCEzDwcOAI4OSKOAj4FXJqZc4EtwMJ2Axm0kmqlUx1tbvdE62Vva0vgBOC61v4lwPx2NRm0kmqlQYx5i4j+iFg5bOsfPlZETI6Iu4HNwHLgf4FHMnOo9ZENwAHtavJgmKRaGc+dbDJzABgY5f0GcERETANuAF4+0sfa/Y5BK6lWmgVWHWTmIxFxK3AUMC0ielpd7YHAxnbfd+pAUq3kOLbRRMQLWp0sETEVOAlYA9wCvLn1sQXAsnY12dFKqpUOnoI7B1gSEZPZ3pQuzcybIuLHwNUR8XHgLmBRu4EMWkm10ozOTB1k5g+BV42wfy1w5HjGMmgl1Uqj6gJGYNBKqpXxrDqYKAatpFopsepgVxm0kmrFW9lIUmFOHUhSYd5hQZIKa9jRSlJZdrSSVJhBK0mFdeEtwwxaSfViRytJhXkKriQV5jpaSSrMqQNJKsyglaTCvNaBJBXmHK0kFeaqA0kqrNmFkwcGraRa8WCYJBXWff2sQSupZuxoJamwoei+ntaglVQr3RezMKnqAiSpk5rj2EYTES+KiFsiYk1E3BsR72/tnxERyyPi/tbj9HY1GbSSaqVJjnlrYwg4JzNfDhwFnBURhwHnASsycy6wovV6VAatpFrJcWyjjpO5KTP/p/X8cWANcABwGrCk9bElwPx2NRm0kmplPFMHEdEfESuHbf0jjRkRBwGvAm4HZmfmJtgexsCsdjV5MExSrTTGcTgsMweAgdE+ExH7Al8HPpCZj0WM/2IKdrSSaqVTB8MAIqKX7SH71cy8vrX7oYiY03p/DrC53TgGraRayXH8GU1sb10XAWsy85Jhb90ILGg9XwAsa1eTUweSaqWDZ4YdA/wV8KOIuLu173zgYmBpRCwE1gOntxvIoJ0Ae+3Vx7eXL2Wvvj56eibzjW98i4s+flnVZakqMYl9L7yC5pZf8+Sl//TM7ilvfy99x57MY+9+U4XF7f46dfWuzLwNeK4J2RPHM5ZBOwGefnobp57yVrZufZKenh6Wr7iW73z7Vu688+72X1bt9L3hL2hsXE9M3eeZfZMPehmx974VVlUfnhm2B9u69UkAent76O3t6cq/DCovps+k9/BXs+0//2PYzklMOePd/PaaUQ9+a4yGyDFvE8WgnSCTJk3i+z/4Jj/7+Uq+u+I2VtrN7pGmvu0snlo6APn7f+R9J81n8K7vk4/+psLK6qNTB8M6aaeDNiLeNcp7zywCHhx6fGd/olaazSavOepUDpl7NPPmHc5hh72s6pI0wXoOP4rmY1torrv/mX0xbT96jzyObctvqLCyeunk8q5OicydS/WIWJ+ZL273uX33Ptj/JT/Lh87/O7ZufYp/ufzKqkupzIOnv7TqEibcXqcvpO81fwqNBvT2EVP3hqFBcnAQBrcBEPvNovmrTTzxwXdUXG01nr9kxS7fWvFdB/3lmDNn8bqvT8itHEc9GBYRP3yut4DZnS+nnmbOnMHg4CCPPvo4U6bsxetf/1ouueTzVZelCfb0tYt4+tpFAEw+9HD2OuUt/2/VAcDz/vWmPTZkO2V3vPD3bODPgC3P2h/A94tUVEOzXziLgSs/w+RJk5k0Kbj++m9y87e+W3VZUi01dvJ/6SW1C9qbgH0zc4cjNxFxa5GKauje1fdxzNGujdTvNe67hyfvu2eH/a6h3XW73V1wM3PhKO+9tfPlSNKumcjVBGPlCQuSamV3nKOVpN3Kbjd1IEm7G6cOJKmw3XHVgSTtVpw6kKTCPBgmSYU5RytJhTl1IEmF7eyFskoyaCXVynhuNz5RDFpJteLUgSQV5tSBJBVmRytJhbm8S5IK8xRcSSqsG6cOvN24pFppkmPe2omIL0bE5ohYPWzfjIhYHhH3tx6ntxvHoJVUK5k55m0MvgSc/Kx95wErMnMusKL1elQGraRa6WRHm5nfA37zrN2nAUtaz5cA89uNY9BKqpUcx5+I6I+IlcO2/jH8xOzM3ATQepzV7gseDJNUK40c+4USM3MAGChXzXYGraRamYAzwx6KiDmZuSki5gCb233BqQNJtdLJOdrncCOwoPV8AbCs3RfsaCXVSifPDIuIq4DjgZkRsQH4CHAxsDQiFgLrgdPbjWPQSqqVZgenDjLzzOd468TxjGPQSqoVr3UgSYWNZ9XBRDFoJdVKJ6cOOsWglVQrTh1IUmF2tJJUmB2tJBXWyEbVJezAoJVUK96cUZIK68Y7LBi0kmrFjlaSCnPVgSQV5qoDSSrMU3AlqTDnaCWpMOdoJakwO1pJKsx1tJJUmB2tJBXmqgNJKsyDYZJUmFMHklSYZ4ZJUmF2tJJUWDfO0UY3pn9dRUR/Zg5UXYe6i38v6m9S1QXsYfqrLkBdyb8XNWfQSlJhBq0kFWbQTizn4TQS/17UnAfDJKkwO1pJKsyglaTCDNoJEhEnR8RPIuKBiDiv6npUvYj4YkRsjojVVdeisgzaCRARk4HPAacAhwFnRsRh1ValLvAl4OSqi1B5Bu3EOBJ4IDPXZuY24GrgtIprUsUy83vAb6quQ+UZtBPjAOAXw15vaO2TtAcwaCdGjLDPdXXSHsKgnRgbgBcNe30gsLGiWiRNMIN2YtwJzI2IgyOiDzgDuLHimiRNEIN2AmTmEPBe4NvAGmBpZt5bbVWqWkRcBfw3cEhEbIiIhVXXpDI8BVeSCrOjlaTCDFpJKsyglaTCDFpJKsyglaTCDFpJKsyglaTC/g8uIFOqxkCj1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Accuracy after traning\n",
    "(66+44)/114 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  14: K-Fold Cross Validation using Keras Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. keras classification\n",
    "2. cross validation score\n",
    "3. Dence Layer\n",
    "\n",
    "by using this methods train our model again and check the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following function call in to function and decide the ephocs quantity\n",
    "1. Classifier\n",
    "2. Input Hidden layers\n",
    "3. Compilation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30))\n",
    "    model.add(Dense(output_dim=16,init='uniform',activation='relu'))\n",
    "    model.add(Dense(output_dim = 1,init='uniform',activation='sigmoid'))\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=built_model,batch_size=100,epochs=100) \n",
    "acciracies = cross_val_score(estimator=model,X= x_train, y= y_train,cv=10,n_jobs=-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.97826087, 0.95652175,\n",
       "       0.95555556, 0.97777778, 1.        , 0.97777778, 0.97777778])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acciracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9823671519756317"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acciracies.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016463791332592098"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acciracies.std()  #Standard derivation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = acciracies.mean(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
